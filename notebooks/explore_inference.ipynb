{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "from zoneinfo import ZoneInfo\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import geopandas as gpd\n",
    "import importlib\n",
    "import contextily as cx\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "px.set_mapbox_access_token(os.environ[\"MAPBOX_TOKEN\"])\n",
    "import plotly.express as px\n",
    "import lightning.pytorch as pl\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "import seaborn as sns\n",
    "import shapely\n",
    "import statsmodels.api as sm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from openbustools import plotting, spatial, standardfeeds\n",
    "from openbustools.traveltime import data_loader, model_utils\n",
    "from openbustools.drivecycle import trajectory\n",
    "from openbustools.drivecycle.physics import conditions, energy, vehicle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose Model and Dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_workers=4\n",
    "    pin_memory=True\n",
    "    accelerator=\"cuda\"\n",
    "else:\n",
    "    num_workers=0\n",
    "    pin_memory=False\n",
    "    accelerator=\"cpu\"\n",
    "\n",
    "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"lightning.pytorch.accelerators.cuda\").setLevel(logging.ERROR)\n",
    "\n",
    "train_data_folders = [f\"../data/kcm_realtime/processed/\"]\n",
    "test_data_folders = [f\"../data/atb_realtime/processed/\"]\n",
    "train_days = standardfeeds.get_date_list('2023_03_15', 30)\n",
    "train_days = [x.split(\".\")[0] for x in train_days]\n",
    "test_days = standardfeeds.get_date_list('2023_04_15', 7)\n",
    "test_days = [x.split(\".\")[0] for x in test_days]\n",
    "\n",
    "model = model_utils.load_model(\"../logs/\", \"kcm\", \"GRU\", 0)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on Holdout Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = data_loader.NumpyDataset(\n",
    "    train_data_folders,\n",
    "    test_days,\n",
    "    holdout_routes=model.holdout_routes,\n",
    "    load_in_memory=True,\n",
    "    config = model.config,\n",
    "    only_holdouts=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    collate_fn=model.collate_fn,\n",
    "    batch_size=model.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=accelerator,\n",
    "    logger=False,\n",
    "    inference_mode=True\n",
    ")\n",
    "preds_and_labels = trainer.predict(model=model, dataloaders=test_loader)\n",
    "\n",
    "# Extract predictions for full shingles, and for individual points\n",
    "all_preds = np.concatenate([x['preds'] for x in preds_and_labels])\n",
    "all_labels = np.concatenate([x['labels'] for x in preds_and_labels])\n",
    "\n",
    "all_preds_raw = np.concatenate([x['preds_raw'][x['mask']] for x in preds_and_labels])\n",
    "all_labels_raw = np.concatenate([x['labels_raw'][x['mask']] for x in preds_and_labels])\n",
    "\n",
    "mape = np.mean(np.abs(all_preds - all_labels) / all_labels)\n",
    "mape_raw = np.mean(np.abs(all_preds_raw - all_labels_raw) / all_labels_raw)\n",
    "mae = np.mean(np.abs(all_preds - all_labels))\n",
    "mae_raw = np.mean(np.abs(all_preds_raw - all_labels_raw))\n",
    "rmse = np.sqrt(np.mean(np.square(all_preds - all_labels)))\n",
    "rmse_raw = np.sqrt(np.mean(np.square(all_preds_raw - all_labels_raw)))\n",
    "\n",
    "print(f\"MAPE: {mape:.2f}, MAPE PT {mape_raw:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}, MAE PT {mae_raw:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}, RMSE PT {rmse_raw:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the input features, labels and predictions into analysis dataframe\n",
    "all_samples = []\n",
    "for i in range(len(test_dataset)):\n",
    "    sample = test_dataset.find_sample(i)\n",
    "    sample = np.concatenate([sample, np.ones((sample.shape[0], 1)) * i], axis=1)\n",
    "    all_samples.append(sample)\n",
    "all_samples = np.concatenate(all_samples)\n",
    "all_samples = pd.DataFrame(all_samples, columns=data_loader.NUM_FEAT_COLS+[\"shingle_id\"])\n",
    "\n",
    "# Add predicted/labeled times to the dataframe, with masked out first prediction for each shingle\n",
    "all_samples['n'] = all_samples.groupby('shingle_id').cumcount()\n",
    "all_samples.loc[all_samples['n'] == 0, 'preds'] = 0\n",
    "all_samples.loc[all_samples['n'] != 0, 'preds'] = all_preds_raw\n",
    "all_samples.loc[all_samples['n'] == 0, 'labels'] = 0\n",
    "all_samples.loc[all_samples['n'] != 0, 'labels'] = all_labels_raw\n",
    "\n",
    "# Calculate residuals\n",
    "all_samples['residuals'] = np.abs(all_samples['preds'] - all_samples['labels'])\n",
    "all_samples['residuals_sq'] = (all_samples['preds'] - all_samples['labels']) ** 2\n",
    "all_samples = gpd.GeoDataFrame(all_samples, geometry=gpd.points_from_xy(all_samples.x, all_samples.y), crs=\"EPSG:32148\")\n",
    "\n",
    "# Reproject to WGS84\n",
    "all_samples = all_samples.to_crs(\"EPSG:4326\")\n",
    "all_samples['lon'] = all_samples.geometry.x\n",
    "all_samples['lat'] = all_samples.geometry.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(all_samples['residuals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ff.create_hexbin_mapbox(\n",
    "    data_frame=all_samples,\n",
    "    lat=\"lat\",\n",
    "    lon=\"lon\",\n",
    "    width=500,\n",
    "    height=700,\n",
    "    nx_hexagon=30,\n",
    "    labels={\"color\": \"MAE\"},\n",
    "    color=\"residuals\",\n",
    "    agg_func=np.mean,\n",
    "    color_continuous_scale=\"Icefire\",\n",
    "    range_color=[0,20],\n",
    "    mapbox_style='open-street-map',\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gtfs = standardfeeds.get_gtfs_shapes_lookup(\"../data/kcm_gtfs/2023_01_23/\")\n",
    "# gtfs_shapes = standardfeeds.get_gtfs_shapes(\"../data/kcm_gtfs/2023_01_23/\", epsg=32148)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the pickle files, splitting holdout and non-holdout samples\n",
    "# res = {}\n",
    "# all_holdout_shingles = []\n",
    "# all_other_shingles = []\n",
    "# for day in train_days:\n",
    "#     print(day)\n",
    "#     shingles = pd.read_pickle(Path('..', 'data', 'kcm_realtime', 'processed', 'analysis',f\"{day}.pkl\"))\n",
    "#     holdout_shingles = shingles[shingles['route_id'].isin(model.holdout_routes)].sample(10)\n",
    "#     other_shingles = shingles[~shingles['route_id'].isin(model.holdout_routes)].sample(10)\n",
    "#     all_holdout_shingles.append(holdout_shingles)\n",
    "#     all_other_shingles.append(other_shingles)\n",
    "# all_holdout_shingles = pd.concat(all_holdout_shingles)\n",
    "# all_other_shingles = pd.concat(all_other_shingles)\n",
    "\n",
    "# print(pd.unique(all_holdout_shingles['route_id']))\n",
    "# print([x in pd.unique(all_other_shingles['route_id']) for x in pd.unique(all_holdout_shingles['route_id'])])\n",
    "# print(pd.unique(all_other_shingles['route_id']))\n",
    "# holdout_routes_in_data = pd.unique(all_holdout_shingles['route_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the holdout shapes over heatmap of all other shingles\n",
    "# df = all_other_shingles\n",
    "# holdout_shapes = gtfs_shapes[gtfs_shapes['route_id'].isin(holdout_routes_in_data)].groupby('route_id').nth(0)\n",
    "\n",
    "# fig, axes = plt.subplots(1, 1, figsize=(10,10))\n",
    "# sns.kdeplot(ax=axes, x=df.x, y=df.y, cmap=\"Reds\", fill=True, bw_adjust=.4)\n",
    "# holdout_shapes.plot(ax=axes, column='route_id', linewidth=3)\n",
    "# cx.add_basemap(ax=axes, crs=holdout_shapes.crs.to_string(), alpha=0.3, source=cx.providers.MapBox(accessToken=os.getenv(key=\"MAPBOX_TOKEN\")))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on All Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = data_loader.NumpyDataset(\n",
    "    train_data_folders,\n",
    "    test_days,\n",
    "    holdout_routes=model.holdout_routes,\n",
    "    load_in_memory=True,\n",
    "    config = model.config,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    collate_fn=model.collate_fn,\n",
    "    batch_size=model.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=accelerator,\n",
    "    logger=False,\n",
    "    inference_mode=True\n",
    ")\n",
    "preds_and_labels = trainer.predict(model=model, dataloaders=test_loader)\n",
    "\n",
    "# Extract predictions for full shingles, and for individual points\n",
    "all_preds = np.concatenate([x['preds'] for x in preds_and_labels])\n",
    "all_labels = np.concatenate([x['labels'] for x in preds_and_labels])\n",
    "\n",
    "all_preds_raw = np.concatenate([x['preds_raw'][x['mask']] for x in preds_and_labels])\n",
    "all_labels_raw = np.concatenate([x['labels_raw'][x['mask']] for x in preds_and_labels])\n",
    "\n",
    "mape = np.mean(np.abs(all_preds - all_labels) / all_labels)\n",
    "mape_raw = np.mean(np.abs(all_preds_raw - all_labels_raw) / all_labels_raw)\n",
    "mae = np.mean(np.abs(all_preds - all_labels))\n",
    "mae_raw = np.mean(np.abs(all_preds_raw - all_labels_raw))\n",
    "rmse = np.sqrt(np.mean(np.square(all_preds - all_labels)))\n",
    "rmse_raw = np.sqrt(np.mean(np.square(all_preds_raw - all_labels_raw)))\n",
    "\n",
    "print(f\"MAPE: {mape:.2f}, MAPE PT {mape_raw:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}, MAE PT {mae_raw:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}, RMSE PT {rmse_raw:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the input features, labels and predictions into analysis dataframe\n",
    "all_samples = []\n",
    "for i in range(len(test_dataset)):\n",
    "    sample = test_dataset.find_sample(i)\n",
    "    sample = np.concatenate([sample, np.ones((sample.shape[0], 1)) * i], axis=1)\n",
    "    all_samples.append(sample)\n",
    "all_samples = np.concatenate(all_samples)\n",
    "all_samples = pd.DataFrame(all_samples, columns=data_loader.NUM_FEAT_COLS+[\"shingle_id\"])\n",
    "\n",
    "# Add predicted/labeled times to the dataframe, with masked out first prediction for each shingle\n",
    "all_samples['n'] = all_samples.groupby('shingle_id').cumcount()\n",
    "all_samples.loc[all_samples['n'] == 0, 'preds'] = 0\n",
    "all_samples.loc[all_samples['n'] != 0, 'preds'] = all_preds_raw\n",
    "all_samples.loc[all_samples['n'] == 0, 'labels'] = 0\n",
    "all_samples.loc[all_samples['n'] != 0, 'labels'] = all_labels_raw\n",
    "\n",
    "# Calculate residuals\n",
    "all_samples['residuals'] = np.abs(all_samples['preds'] - all_samples['labels'])\n",
    "all_samples['residuals_sq'] = (all_samples['preds'] - all_samples['labels']) ** 2\n",
    "all_samples = gpd.GeoDataFrame(all_samples, geometry=gpd.points_from_xy(all_samples.x, all_samples.y), crs=\"EPSG:32148\")\n",
    "\n",
    "# Reproject to WGS84\n",
    "all_samples = all_samples.to_crs(\"EPSG:4326\")\n",
    "all_samples['lon'] = all_samples.geometry.x\n",
    "all_samples['lat'] = all_samples.geometry.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(all_samples['residuals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ff.create_hexbin_mapbox(\n",
    "    data_frame=all_samples.sample(100000),\n",
    "    lat=\"lat\",\n",
    "    lon=\"lon\",\n",
    "    width=500,\n",
    "    height=700,\n",
    "    nx_hexagon=200,\n",
    "    labels={\"color\": \"MAE\"},\n",
    "    color=\"residuals\",\n",
    "    agg_func=np.mean,\n",
    "    color_continuous_scale=\"Icefire\",\n",
    "    range_color=[0,20],\n",
    "    mapbox_style='open-street-map',\n",
    ")\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "valle_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b30fe1de1713ca8e7537eef068b13a2de77ded03f86aab2e80ea73416dd3d704"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
