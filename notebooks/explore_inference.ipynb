{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import sys\n",
    "from zoneinfo import ZoneInfo\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import geopandas as gpd\n",
    "import importlib\n",
    "import contextily as cx\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import plotly.figure_factory as ff\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "px.set_mapbox_access_token(os.environ[\"MAPBOX_TOKEN\"])\n",
    "import plotly.express as px\n",
    "import lightning.pytorch as pl\n",
    "import rasterio as rio\n",
    "from rasterio.plot import show\n",
    "import seaborn as sns\n",
    "import shapely\n",
    "import statsmodels.api as sm\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from openbustools import plotting, spatial, standardfeeds\n",
    "from openbustools.traveltime import data_loader, model_utils\n",
    "from openbustools.drivecycle import trajectory\n",
    "from openbustools.drivecycle.physics import conditions, energy, vehicle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    num_workers=4\n",
    "    pin_memory=True\n",
    "    accelerator=\"cuda\"\n",
    "else:\n",
    "    num_workers=0\n",
    "    pin_memory=False\n",
    "    accelerator=\"cpu\"\n",
    "\n",
    "logging.getLogger(\"lightning\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"pytorch_lightning\").setLevel(logging.ERROR)\n",
    "logging.getLogger(\"lightning.pytorch.accelerators.cuda\").setLevel(logging.ERROR)\n",
    "\n",
    "model = model_utils.load_model(\"../logs/saved_models/\", \"kcm_1month_resampled\", \"GRU\", 0)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_folders = [f\"../data/kcm_realtime/processed/\"]\n",
    "test_data_folders = [f\"../data/atb_realtime/processed/\"]\n",
    "train_dates = standardfeeds.get_date_list('2023_03_15', 30)\n",
    "test_dates = standardfeeds.get_date_list('2023_04_15', 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on Holdout Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_data, holdout_routes, holdout_config = data_loader.load_h5(train_data_folders, test_dates, only_holdout=True, holdout_routes=model.holdout_routes, config=model.config)\n",
    "holdout_dataset = data_loader.H5Dataset(holdout_data)\n",
    "holdout_dataset.include_grid = model.include_grid\n",
    "\n",
    "test_data, holdout_routes, test_config = data_loader.load_h5(train_data_folders, test_dates, only_holdout=False, holdout_routes=model.holdout_routes, config=model.config)\n",
    "test_dataset = data_loader.H5Dataset(test_data)\n",
    "test_dataset.include_grid = model.include_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gtfs = standardfeeds.get_gtfs_shapes_lookup(\"../data/kcm_gtfs/2023_01_23/\")\n",
    "gtfs_shapes = standardfeeds.get_gtfs_shapes(\"../data/kcm_gtfs/2023_01_23/\", epsg=32148)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Read the pickle files, splitting holdout and non-holdout samples\n",
    "# res = {}\n",
    "# all_holdout_shingles = []\n",
    "# all_other_shingles = []\n",
    "# for day in train_dates:\n",
    "#     print(day)\n",
    "#     shingles = pd.read_pickle(Path('..', 'data', 'kcm_realtime', 'processed', day))\n",
    "#     holdout_shingles = shingles[shingles['route_id'].isin(model.holdout_routes)].sample(10)\n",
    "#     other_shingles = shingles[~shingles['route_id'].isin(model.holdout_routes)].sample(10)\n",
    "#     all_holdout_shingles.append(holdout_shingles)\n",
    "#     all_other_shingles.append(other_shingles)\n",
    "# all_holdout_shingles = pd.concat(all_holdout_shingles)\n",
    "# all_other_shingles = pd.concat(all_other_shingles)\n",
    "\n",
    "# print(pd.unique(all_holdout_shingles['route_id']))\n",
    "# print([x in pd.unique(all_other_shingles['route_id']) for x in pd.unique(all_holdout_shingles['route_id'])])\n",
    "# print(pd.unique(all_other_shingles['route_id']))\n",
    "# holdout_routes_in_data = pd.unique(all_holdout_shingles['route_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_other_shingles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Plot the holdout shapes over heatmap of all other shingles\n",
    "# df = all_other_shingles\n",
    "# holdout_shapes = gtfs_shapes[gtfs_shapes['route_id'].isin(holdout_routes_in_data)].groupby('route_id').nth(0)\n",
    "\n",
    "# fig, axes = plt.subplots(1, 1, figsize=(10,10))\n",
    "# sns.kdeplot(ax=axes, x=df.x, y=df.y, cmap=\"Reds\", fill=True, bw_adjust=.4)\n",
    "# holdout_shapes.plot(ax=axes, column='route_id', linewidth=3)\n",
    "# cx.add_basemap(ax=axes, crs=holdout_shapes.crs.to_string(), alpha=0.3, source=cx.providers.MapBox(accessToken=os.getenv(key=\"MAPBOX_TOKEN\")))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for the holdout route shingles\n",
    "loader = DataLoader(\n",
    "    holdout_dataset,\n",
    "    collate_fn=model.collate_fn,\n",
    "    batch_size=model.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=accelerator,\n",
    "    logger=False,\n",
    "    inference_mode=True,\n",
    "    enable_progress_bar=False,\n",
    "    enable_model_summary=False,\n",
    ")\n",
    "preds_and_labels = trainer.predict(model=model, dataloaders=loader)\n",
    "\n",
    "# Extract predictions for full shingles, and for individual points\n",
    "all_preds = np.concatenate([x['preds'] for x in preds_and_labels])\n",
    "all_labels = np.concatenate([x['labels'] for x in preds_and_labels])\n",
    "\n",
    "all_preds_raw = np.concatenate([x['preds_raw'][x['mask']] for x in preds_and_labels])\n",
    "all_labels_raw = np.concatenate([x['labels_raw'][x['mask']] for x in preds_and_labels])\n",
    "\n",
    "mape = np.mean(np.abs(all_preds - all_labels) / all_labels)\n",
    "mape_raw = np.mean(np.abs(all_preds_raw - all_labels_raw) / all_labels_raw)\n",
    "mae = np.mean(np.abs(all_preds - all_labels))\n",
    "mae_raw = np.mean(np.abs(all_preds_raw - all_labels_raw))\n",
    "rmse = np.sqrt(np.mean(np.square(all_preds - all_labels)))\n",
    "rmse_raw = np.sqrt(np.mean(np.square(all_preds_raw - all_labels_raw)))\n",
    "\n",
    "print(f\"MAPE: {mape:.2f}, MAPE PT {mape_raw:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}, MAE PT {mae_raw:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}, RMSE PT {rmse_raw:.2f}\")\n",
    "\n",
    "# Extract the input features from the dataset at the point-level\n",
    "shingles = []\n",
    "for i in range(len(holdout_data)):\n",
    "    # Skip the first element of each shingle, which is the start point\n",
    "    shingle = holdout_data[i]['feats_n'][1:]\n",
    "    shingles.append(shingle)\n",
    "shingles = np.concatenate(shingles)\n",
    "\n",
    "# Combine the input features, labels and predictions into analysis dataframe\n",
    "df = pd.DataFrame(shingles, columns=data_loader.NUM_FEAT_COLS)\n",
    "df['preds'] = all_preds_raw\n",
    "df['labels'] = all_labels_raw\n",
    "df['residuals'] = np.abs(df['preds'] - df['labels'])\n",
    "df['residuals_sq'] = (df['preds'] - df['labels']) ** 2\n",
    "df = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.x, df.y), crs=\"EPSG:32148\")\n",
    "\n",
    "# Reproject to WGS84\n",
    "df = df.to_crs(\"EPSG:4326\")\n",
    "df['lon'] = df.geometry.x\n",
    "df['lat'] = df.geometry.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df['residuals'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ff.create_hexbin_mapbox(\n",
    "    data_frame=df,\n",
    "    lat=\"lat\",\n",
    "    lon=\"lon\",\n",
    "    width=500,\n",
    "    height=700,\n",
    "    nx_hexagon=30,\n",
    "    labels={\"color\": \"MAE\"},\n",
    "    color=\"residuals\",\n",
    "    agg_func=np.mean,\n",
    "    color_continuous_scale=\"Icefire\",\n",
    "    range_color=[2,3],\n",
    "    mapbox_style='open-street-map',\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ff.create_hexbin_mapbox(\n",
    "    data_frame=df,\n",
    "    lat=\"lat\",\n",
    "    lon=\"lon\",\n",
    "    width=500,\n",
    "    height=700,\n",
    "    nx_hexagon=20,\n",
    "    opacity=0.9,\n",
    "    labels={\"color\": \"Std. Residuals\"},\n",
    "    color=\"residuals\",\n",
    "    agg_func=np.std,\n",
    "    color_continuous_scale=\"Icefire\",\n",
    "    range_color=[2,5]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ff.create_hexbin_mapbox(\n",
    "    data_frame=df,\n",
    "    lat=\"lat\",\n",
    "    lon=\"lon\",\n",
    "    width=500,\n",
    "    height=700,\n",
    "    nx_hexagon=20,\n",
    "    opacity=0.9,\n",
    "    labels={\"color\": \"Avg. Speed (m/s)\"},\n",
    "    color=\"calc_speed_m_s\",\n",
    "    agg_func=np.mean,\n",
    "    color_continuous_scale=\"Icefire\",\n",
    "    range_color=[0,20]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = ff.create_hexbin_mapbox(\n",
    "    data_frame=df,\n",
    "    lat=\"lat\",\n",
    "    lon=\"lon\",\n",
    "    width=500,\n",
    "    height=700,\n",
    "    nx_hexagon=20,\n",
    "    opacity=0.9,\n",
    "    labels={\"color\": \"Std. Speed (m/s)\"},\n",
    "    color=\"calc_speed_m_s\",\n",
    "    agg_func=np.std,\n",
    "    color_continuous_scale=\"Icefire\",\n",
    "    range_color=[0,8]\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_df = df[df['MAPE']<1].copy()\n",
    "# fig, axes = plt.subplots(1, 1, figsize=(10,10))\n",
    "# plt.hexbin(plot_df.x, plot_df.y, plot_df.MAPE, cmap='plasma', gridsize=15)\n",
    "# sns.kdeplot(ax=axes, x=plot_df.x, y=plot_df.y, weights=plot_df.MAPE, cmap=\"plasma\", fill=True, bw_adjust=.2)\n",
    "# cx.add_basemap(ax=axes, crs=plot_df.crs.to_string(), alpha=0.3, source=cx.providers.MapBox(accessToken=os.getenv(key=\"MAPBOX_TOKEN\")))\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference on All Routes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions for all route shingles\n",
    "loader = DataLoader(\n",
    "    test_dataset,\n",
    "    collate_fn=model.collate_fn,\n",
    "    batch_size=model.batch_size,\n",
    "    shuffle=False,\n",
    "    drop_last=False,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=pin_memory\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=accelerator,\n",
    "    logger=False,\n",
    "    inference_mode=True,\n",
    "    enable_progress_bar=False,\n",
    "    enable_model_summary=False,\n",
    ")\n",
    "preds_and_labels = trainer.predict(model=model, dataloaders=loader)\n",
    "\n",
    "# Extract predictions for full shingles, and for individual points\n",
    "all_preds = np.concatenate([x['preds'] for x in preds_and_labels])\n",
    "all_labels = np.concatenate([x['labels'] for x in preds_and_labels])\n",
    "\n",
    "all_preds_raw = np.concatenate([x['preds_raw'][x['mask']] for x in preds_and_labels])\n",
    "all_labels_raw = np.concatenate([x['labels_raw'][x['mask']] for x in preds_and_labels])\n",
    "\n",
    "mape = np.mean(np.abs(all_preds - all_labels) / all_labels)\n",
    "mape_raw = np.mean(np.abs(all_preds_raw - all_labels_raw) / all_labels_raw)\n",
    "mae = np.mean(np.abs(all_preds - all_labels))\n",
    "mae_raw = np.mean(np.abs(all_preds_raw - all_labels_raw))\n",
    "rmse = np.sqrt(np.mean(np.square(all_preds - all_labels)))\n",
    "rmse_raw = np.sqrt(np.mean(np.square(all_preds_raw - all_labels_raw)))\n",
    "\n",
    "print(f\"MAPE: {mape:.2f}, MAPE PT {mape_raw:.2f}\")\n",
    "print(f\"MAE: {mae:.2f}, MAE PT {mae_raw:.2f}\")\n",
    "print(f\"RMSE: {rmse:.2f}, RMSE PT {rmse_raw:.2f}\")\n",
    "\n",
    "# Extract the input features from the dataset at the point-level\n",
    "shingles = []\n",
    "for i in range(len(test_data)):\n",
    "    # Skip the first element of each shingle, which is the start point\n",
    "    shingle = test_data[i]['feats_n'][1:]\n",
    "    shingles.append(shingle)\n",
    "shingles = np.concatenate(shingles)\n",
    "\n",
    "# Combine the input features, labels and predictions into analysis dataframe\n",
    "df = pd.DataFrame(shingles, columns=data_loader.NUM_FEAT_COLS)\n",
    "df['preds'] = all_preds_raw\n",
    "df['labels'] = all_labels_raw\n",
    "df['residuals'] = np.abs(df['preds'] - df['labels'])\n",
    "df['residuals_sq'] = (df['preds'] - df['labels']) ** 2\n",
    "df['pred_speed_m_s'] = df['calc_dist_m'] / df['preds']\n",
    "df = gpd.GeoDataFrame(df, geometry=gpd.points_from_xy(df.x, df.y), crs=\"EPSG:32148\")\n",
    "\n",
    "# Reproject to WGS84\n",
    "df = df.to_crs(\"EPSG:4326\")\n",
    "df['lon'] = df.geometry.x\n",
    "df['lat'] = df.geometry.y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = ff.create_hexbin_mapbox(\n",
    "#     data_frame=df,\n",
    "#     lat=\"lat\",\n",
    "#     lon=\"lon\",\n",
    "#     width=1000,\n",
    "#     height=1200,\n",
    "#     nx_hexagon=200,\n",
    "#     labels={\"color\": \"MAE\"},\n",
    "#     color=\"residuals\",\n",
    "#     agg_func=np.mean,\n",
    "#     color_continuous_scale=\"Icefire\",\n",
    "#     range_color=[1.5,3.5],\n",
    "#     mapbox_style='open-street-map',\n",
    "# )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = ff.create_hexbin_mapbox(\n",
    "#     data_frame=df,\n",
    "#     lat=\"lat\",\n",
    "#     lon=\"lon\",\n",
    "#     width=1000,\n",
    "#     height=1200,\n",
    "#     nx_hexagon=100,\n",
    "#     labels={\"color\": \"MAE\"},\n",
    "#     color=\"calc_speed_m_s\",\n",
    "#     agg_func=np.mean,\n",
    "#     color_continuous_scale=\"Icefire\",\n",
    "#     range_color=[0,30],\n",
    "#     mapbox_style='open-street-map',\n",
    "# )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = ff.create_hexbin_mapbox(\n",
    "#     data_frame=df,\n",
    "#     lat=\"lat\",\n",
    "#     lon=\"lon\",\n",
    "#     width=1000,\n",
    "#     height=1200,\n",
    "#     nx_hexagon=100,\n",
    "#     labels={\"color\": \"MAE\"},\n",
    "#     color=\"calc_speed_m_s\",\n",
    "#     agg_func=np.std,\n",
    "#     color_continuous_scale=\"Icefire\",\n",
    "#     range_color=[0,10],\n",
    "#     mapbox_style='open-street-map',\n",
    "# )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = ff.create_hexbin_mapbox(\n",
    "#     data_frame=df,\n",
    "#     lat=\"lat\",\n",
    "#     lon=\"lon\",\n",
    "#     width=1000,\n",
    "#     height=1200,\n",
    "#     nx_hexagon=100,\n",
    "#     labels={\"color\": \"MAE\"},\n",
    "#     color=\"pred_speed_m_s\",\n",
    "#     agg_func=np.mean,\n",
    "#     color_continuous_scale=\"Icefire\",\n",
    "#     range_color=[0,30],\n",
    "#     mapbox_style='open-street-map',\n",
    "# )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig = ff.create_hexbin_mapbox(\n",
    "#     data_frame=df,\n",
    "#     lat=\"lat\",\n",
    "#     lon=\"lon\",\n",
    "#     width=1000,\n",
    "#     height=1200,\n",
    "#     nx_hexagon=100,\n",
    "#     labels={\"color\": \"MAE\"},\n",
    "#     color=\"pred_speed_m_s\",\n",
    "#     agg_func=np.std,\n",
    "#     color_continuous_scale=\"Icefire\",\n",
    "#     range_color=[0,100],\n",
    "#     mapbox_style='open-street-map',\n",
    "# )\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "valle_m1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b30fe1de1713ca8e7537eef068b13a2de77ded03f86aab2e80ea73416dd3d704"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
